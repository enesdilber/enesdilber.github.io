{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STATS 306 WI 2020, HW 4, _25 points_\n",
    "\n",
    "Assigned: 03/23/2020\n",
    "\n",
    "Due: 04/06/2020 at 11:59 pm (no credit for late submissions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.0     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.3\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 2.1.3     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 0.8.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 1.3.1     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.0\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(tidyverse)\n",
    "library(stringr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1, _5 points_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no right or wrong answers for this problem. I am just including it to make HW 4 a bit less stressful as we all continue to learn how to deal with the COVID-19 pandemic."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** List 5 things that made you smile last week! _1 point_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sth that made you smile\n",
    "- sth that made you smile\n",
    "- sth that made you smile\n",
    "- sth that made you smile\n",
    "- sth that made you smile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** List 4 adjectives that describe your last week! _1 point_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- adj that describes your last week\n",
    "- adj that describes your last week\n",
    "- adj that describes your last week\n",
    "- adj that describes your last week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** List 3 things you are looking forward to in the next week! _1 point_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sth you look forward to\n",
    "- sth you look forward to\n",
    "- sth you look forward to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** List 2 things you learnt last week! _1 point_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- sth you learnt\n",
    "- sth you learnt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)** List 1 goal you have for next week! _1 point_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2, 5 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This problem consists entirely of 1 point parts where the answer is either True or False. Just delete the option that is incorrect leaving the correct answer in the empty cells provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Explicitly missing values in R are marked clearly using the string `\"NA\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False, it's `NA` --not a string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** `complete()` makes missing values explicit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** The argument to `fill()` that sets the direction in which to fill missing values is called `.direction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** `str_replace_na()` can be used to convert occurrences of `NA` into the string `<missing>`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "True `str_replace_na(c('aa', NA), replacement = \"<missing>\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)** `values_drop_na` is an optional argument for both `pivot_wider()` and `pivot_longer()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3, _5 points_\n",
    "\n",
    "In the code output below, don't worry about the greater than sign before `writeLines()`. That's just the R prompt that does not show up in jupyter. I included it below so that it is easy to figure out indentation levels across different lines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **(1)** Create a string and assign to the variable `beckett` such that `writeLines(beckett)` displays the following: _1 point_\n",
    " \n",
    "```\n",
    "> writeLines(beckett)\n",
    "Ever tried. Ever failed. No matter.\n",
    "Try Again. Fail again. Fail better.\n",
    "-- Samuel Beckett\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ever tried. Ever failed. No matter.\n",
      "Try Again. Fail again. Fail better.\n",
      "-- Samuel Beckett\n"
     ]
    }
   ],
   "source": [
    "# I am using str_c to make the line not cutoff\n",
    "beckett = c('Ever tried. Ever failed. No matter.',\n",
    "            'Try Again. Fail again. Fail better.',\n",
    "            '-- Samuel Beckett')\n",
    "beckett = str_c(beckett, collapse = '\\n')\n",
    "writeLines(beckett)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** Create a string and assign to the variable `covid19` such that `writeLines(covid19)` displays the following. Note that the whitespace before the numbers 1, 2, 3, etc. is supposed to be a tab character. _1 point_\n",
    "\n",
    "```\n",
    "> writeLines(covid19)\n",
    "DO THE FIVE\n",
    "Help stop coronavirus\n",
    "\n",
    "\t1. HANDS Wash them often\n",
    "\t2. ELBOW Cough into it\n",
    "\t3. FACE Don't touch it.\n",
    "\t4. SPACE Keep safe distance\n",
    "\t5. HOME Stay if you can\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DO THE FIVE\n",
      "Help stop coronavirus\n",
      "\n",
      "\t1. HANDS Wash them often\n",
      "\t2. ELBOW Cough into it\n",
      "\t3. FACE Don't touch it.\n",
      "\t4. SPACE Keep safe distance\n",
      "\t5. HOME Stay if you can\n"
     ]
    }
   ],
   "source": [
    "covid19 = c('DO THE FIVE',\n",
    "            'Help stop coronavirus',\n",
    "            '\\n\\t1. HANDS Wash them often',\n",
    "            '\\t2. ELBOW Cough into it',\n",
    "            \"\\t3. FACE Don't touch it.\",\n",
    "            '\\t4. SPACE Keep safe distance',\n",
    "            '\\t5. HOME Stay if you can')\n",
    "covid19 = str_c(covid19, collapse = '\\n')\n",
    "writeLines(covid19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** Create a string and assign to the variable `drseuss` such that `writeLines(drseuss)` displays the following: _1 point_\n",
    "\n",
    "```\n",
    "> writeLines(drseuss)\n",
    "The more you READ,\n",
    " the more you know,\n",
    "  the more you LEARN,\n",
    "   the more places\n",
    "    you'll GO!\n",
    "-Dr. Seuss\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The more you READ,\n",
      " the more you know,\n",
      "  the more you LEARN,\n",
      "   the more places\n",
      "    you'll GO!\n",
      "-Dr. Seuss\n"
     ]
    }
   ],
   "source": [
    "drseuss = c('The more you READ,',\n",
    "            ' the more you know,',\n",
    "            '  the more you LEARN,',\n",
    "            '   the more places',\n",
    "            \"    you'll GO!\",\n",
    "            \"-Dr. Seuss\")\n",
    "drseuss = str_c(drseuss, collapse = '\\n')\n",
    "writeLines(drseuss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** Create a string and assign to the variable `its_all_greek_to_me` such that `writeLines(its_all_greek_to_me)` displays the following: _1 point_\n",
    "\n",
    "```\n",
    "> writeLines(its_all_greek_to_me)\n",
    "The first three small greek letters are:\n",
    "α, β, and γ.\n",
    "The first three capital greek letters are:\n",
    "Α, Β, and Γ.\n",
    "```\n",
    "\n",
    "_Hint:_ You can consult [the wikipedia page](https://en.wikipedia.org/wiki/List_of_Unicode_characters) containing a list of unicode characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first three small greek letters are:\n",
      "α, β, and γ.\n",
      "The first three capital greek letters are:\n",
      "Α, Β, and Γ\n"
     ]
    }
   ],
   "source": [
    "its_all_greek_to_me=c('The first three small greek letters are:',\n",
    "                      '\\u03B1, \\u03B2, and \\u03B3.',\n",
    "                      'The first three capital greek letters are:',\n",
    "                      '\\u0391, \\u0392, and \\u0393')\n",
    "its_all_greek_to_me = str_c(its_all_greek_to_me, collapse = '\\n')\n",
    "writeLines(its_all_greek_to_me)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)**  Create a string and assign to the variable `escapes` such that `writeLines(escapes)` displays the following: _1 point_\n",
    "\n",
    "```\n",
    "> writeLines(escapes)\n",
    "The most common are \"\\n\", newline, and \"\\t\", tab.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most common are \"\\n\", newline, and \"\\t\", tab\n"
     ]
    }
   ],
   "source": [
    "escapes = 'The most common are \"\\\\n\", newline, and \"\\\\t\", tab'\n",
    "writeLines(escapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4, _10 points_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(1)** Define the variable `regex` such that it matches three digit dollar amounts of the form \"$xxx\" where each 'x' represents a digit. For example, you should see the following behavior: _2 points_\n",
    "```\n",
    "> x <- c(\"You owe me $100\", \"I spent $10\", \"I gave you $999\", \"We have no money\")\n",
    "> str_detect(x, regex)\n",
    "[1]  TRUE FALSE  TRUE FALSE\n",
    "> str_extract(str_subset(x, regex), regex)\n",
    "[1] \"$100\" \"$999\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>TRUE</li><li>FALSE</li><li>TRUE</li><li>FALSE</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. FALSE\n",
       "3. TRUE\n",
       "4. FALSE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  TRUE FALSE  TRUE FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- c(\"You owe me $100\", \"I spent $10\", \"I gave you $999\", \"We have no money\")\n",
    "regex = \"\\\\$\\\\d{3}\\\\b\"\n",
    "str_detect(x, regex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(2)** The character vector `words` is predefined for you when you load `tidyverse` and `stringr`. Write the command to calculate the number of words in `words` that both start and end in a vowel. _2 points_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "53"
      ],
      "text/latex": [
       "53"
      ],
      "text/markdown": [
       "53"
      ],
      "text/plain": [
       "[1] 53"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(str_detect(words, \"(^[aeiou].*[aeiou]$)|(^[aeiou]$)\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(3)** Define the variable `regex2` such that it matches only those strings that are _entirely_ composed of a dollar-cent amount of the form \"$x···x.yy\". Note that the dollar part \"x···x\" should have one or more digits and the cent part \"yy\" should have exactly two digits. For example, you should see the following behavior: _3 points_\n",
    "```\n",
    "> x <- c(\"$0.99\", \"$1.23 is due\", \"have $0.87\", \"$100.01\", \"$100.0101\")\n",
    "> str_detect(x, regex2)\n",
    "[1]  TRUE FALSE FALSE  TRUE FALSE\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".list-inline {list-style: none; margin:0; padding: 0}\n",
       ".list-inline>li {display: inline-block}\n",
       ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
       "</style>\n",
       "<ol class=list-inline><li>TRUE</li><li>FALSE</li><li>FALSE</li><li>TRUE</li><li>FALSE</li></ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\item FALSE\n",
       "\\item TRUE\n",
       "\\item FALSE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. FALSE\n",
       "3. FALSE\n",
       "4. TRUE\n",
       "5. FALSE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  TRUE FALSE FALSE  TRUE FALSE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x <- c(\"$0.99\", \"$1.23 is due\", \"have $0.87\", \"$100.01\", \"$100.0101\")\n",
    "regex2 = \"^\\\\$\\\\d+\\\\.\\\\d{2}$\"\n",
    "str_detect(x, regex2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(4)** Suppose we create a tibble `df` using\n",
    "```\n",
    "> df <- tibble(word = words, i = seq_along(words))\n",
    "```\n",
    "Then, write a command using `filter` to return exactly those rows of `df` where `word` has more vowels than consonants.  _2 points_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A tibble: 60 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>word</th><th scope=col>i</th></tr>\n",
       "\t<tr><th scope=col>&lt;chr&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>a        </td><td>  1</td></tr>\n",
       "\t<tr><td>about    </td><td>  3</td></tr>\n",
       "\t<tr><td>achieve  </td><td>  7</td></tr>\n",
       "\t<tr><td>again    </td><td> 20</td></tr>\n",
       "\t<tr><td>age      </td><td> 22</td></tr>\n",
       "\t<tr><td>ago      </td><td> 24</td></tr>\n",
       "\t<tr><td>agree    </td><td> 25</td></tr>\n",
       "\t<tr><td>air      </td><td> 26</td></tr>\n",
       "\t<tr><td>america  </td><td> 36</td></tr>\n",
       "\t<tr><td>area     </td><td> 49</td></tr>\n",
       "\t<tr><td>argue    </td><td> 50</td></tr>\n",
       "\t<tr><td>associate</td><td> 57</td></tr>\n",
       "\t<tr><td>available</td><td> 62</td></tr>\n",
       "\t<tr><td>aware    </td><td> 63</td></tr>\n",
       "\t<tr><td>because  </td><td> 80</td></tr>\n",
       "\t<tr><td>believe  </td><td> 86</td></tr>\n",
       "\t<tr><td>cause    </td><td>134</td></tr>\n",
       "\t<tr><td>colleague</td><td>166</td></tr>\n",
       "\t<tr><td>die      </td><td>228</td></tr>\n",
       "\t<tr><td>due      </td><td>250</td></tr>\n",
       "\t<tr><td>eat      </td><td>256</td></tr>\n",
       "\t<tr><td>educate  </td><td>258</td></tr>\n",
       "\t<tr><td>encourage</td><td>268</td></tr>\n",
       "\t<tr><td>equal    </td><td>276</td></tr>\n",
       "\t<tr><td>europe   </td><td>278</td></tr>\n",
       "\t<tr><td>eye      </td><td>296</td></tr>\n",
       "\t<tr><td>house    </td><td>406</td></tr>\n",
       "\t<tr><td>idea     </td><td>412</td></tr>\n",
       "\t<tr><td>imagine  </td><td>415</td></tr>\n",
       "\t<tr><td>issue    </td><td>434</td></tr>\n",
       "\t<tr><td>leave    </td><td>465</td></tr>\n",
       "\t<tr><td>lie      </td><td>472</td></tr>\n",
       "\t<tr><td>measure  </td><td>513</td></tr>\n",
       "\t<tr><td>obvious  </td><td>565</td></tr>\n",
       "\t<tr><td>one      </td><td>577</td></tr>\n",
       "\t<tr><td>operate  </td><td>580</td></tr>\n",
       "\t<tr><td>out      </td><td>590</td></tr>\n",
       "\t<tr><td>piece    </td><td>620</td></tr>\n",
       "\t<tr><td>quiet    </td><td>670</td></tr>\n",
       "\t<tr><td>quite    </td><td>671</td></tr>\n",
       "\t<tr><td>radio    </td><td>672</td></tr>\n",
       "\t<tr><td>raise    </td><td>674</td></tr>\n",
       "\t<tr><td>realise  </td><td>681</td></tr>\n",
       "\t<tr><td>receive  </td><td>684</td></tr>\n",
       "\t<tr><td>require  </td><td>699</td></tr>\n",
       "\t<tr><td>see      </td><td>734</td></tr>\n",
       "\t<tr><td>serious  </td><td>741</td></tr>\n",
       "\t<tr><td>situate  </td><td>771</td></tr>\n",
       "\t<tr><td>tea      </td><td>842</td></tr>\n",
       "\t<tr><td>tie      </td><td>872</td></tr>\n",
       "\t<tr><td>too      </td><td>879</td></tr>\n",
       "\t<tr><td>union    </td><td>904</td></tr>\n",
       "\t<tr><td>unite    </td><td>906</td></tr>\n",
       "\t<tr><td>use      </td><td>912</td></tr>\n",
       "\t<tr><td>usual    </td><td>913</td></tr>\n",
       "\t<tr><td>value    </td><td>914</td></tr>\n",
       "\t<tr><td>various  </td><td>915</td></tr>\n",
       "\t<tr><td>video    </td><td>917</td></tr>\n",
       "\t<tr><td>wee      </td><td>937</td></tr>\n",
       "\t<tr><td>you      </td><td>979</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 60 × 2\n",
       "\\begin{tabular}{ll}\n",
       " word & i\\\\\n",
       " <chr> & <int>\\\\\n",
       "\\hline\n",
       "\t a         &   1\\\\\n",
       "\t about     &   3\\\\\n",
       "\t achieve   &   7\\\\\n",
       "\t again     &  20\\\\\n",
       "\t age       &  22\\\\\n",
       "\t ago       &  24\\\\\n",
       "\t agree     &  25\\\\\n",
       "\t air       &  26\\\\\n",
       "\t america   &  36\\\\\n",
       "\t area      &  49\\\\\n",
       "\t argue     &  50\\\\\n",
       "\t associate &  57\\\\\n",
       "\t available &  62\\\\\n",
       "\t aware     &  63\\\\\n",
       "\t because   &  80\\\\\n",
       "\t believe   &  86\\\\\n",
       "\t cause     & 134\\\\\n",
       "\t colleague & 166\\\\\n",
       "\t die       & 228\\\\\n",
       "\t due       & 250\\\\\n",
       "\t eat       & 256\\\\\n",
       "\t educate   & 258\\\\\n",
       "\t encourage & 268\\\\\n",
       "\t equal     & 276\\\\\n",
       "\t europe    & 278\\\\\n",
       "\t eye       & 296\\\\\n",
       "\t house     & 406\\\\\n",
       "\t idea      & 412\\\\\n",
       "\t imagine   & 415\\\\\n",
       "\t issue     & 434\\\\\n",
       "\t leave     & 465\\\\\n",
       "\t lie       & 472\\\\\n",
       "\t measure   & 513\\\\\n",
       "\t obvious   & 565\\\\\n",
       "\t one       & 577\\\\\n",
       "\t operate   & 580\\\\\n",
       "\t out       & 590\\\\\n",
       "\t piece     & 620\\\\\n",
       "\t quiet     & 670\\\\\n",
       "\t quite     & 671\\\\\n",
       "\t radio     & 672\\\\\n",
       "\t raise     & 674\\\\\n",
       "\t realise   & 681\\\\\n",
       "\t receive   & 684\\\\\n",
       "\t require   & 699\\\\\n",
       "\t see       & 734\\\\\n",
       "\t serious   & 741\\\\\n",
       "\t situate   & 771\\\\\n",
       "\t tea       & 842\\\\\n",
       "\t tie       & 872\\\\\n",
       "\t too       & 879\\\\\n",
       "\t union     & 904\\\\\n",
       "\t unite     & 906\\\\\n",
       "\t use       & 912\\\\\n",
       "\t usual     & 913\\\\\n",
       "\t value     & 914\\\\\n",
       "\t various   & 915\\\\\n",
       "\t video     & 917\\\\\n",
       "\t wee       & 937\\\\\n",
       "\t you       & 979\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 60 × 2\n",
       "\n",
       "| word &lt;chr&gt; | i &lt;int&gt; |\n",
       "|---|---|\n",
       "| a         |   1 |\n",
       "| about     |   3 |\n",
       "| achieve   |   7 |\n",
       "| again     |  20 |\n",
       "| age       |  22 |\n",
       "| ago       |  24 |\n",
       "| agree     |  25 |\n",
       "| air       |  26 |\n",
       "| america   |  36 |\n",
       "| area      |  49 |\n",
       "| argue     |  50 |\n",
       "| associate |  57 |\n",
       "| available |  62 |\n",
       "| aware     |  63 |\n",
       "| because   |  80 |\n",
       "| believe   |  86 |\n",
       "| cause     | 134 |\n",
       "| colleague | 166 |\n",
       "| die       | 228 |\n",
       "| due       | 250 |\n",
       "| eat       | 256 |\n",
       "| educate   | 258 |\n",
       "| encourage | 268 |\n",
       "| equal     | 276 |\n",
       "| europe    | 278 |\n",
       "| eye       | 296 |\n",
       "| house     | 406 |\n",
       "| idea      | 412 |\n",
       "| imagine   | 415 |\n",
       "| issue     | 434 |\n",
       "| leave     | 465 |\n",
       "| lie       | 472 |\n",
       "| measure   | 513 |\n",
       "| obvious   | 565 |\n",
       "| one       | 577 |\n",
       "| operate   | 580 |\n",
       "| out       | 590 |\n",
       "| piece     | 620 |\n",
       "| quiet     | 670 |\n",
       "| quite     | 671 |\n",
       "| radio     | 672 |\n",
       "| raise     | 674 |\n",
       "| realise   | 681 |\n",
       "| receive   | 684 |\n",
       "| require   | 699 |\n",
       "| see       | 734 |\n",
       "| serious   | 741 |\n",
       "| situate   | 771 |\n",
       "| tea       | 842 |\n",
       "| tie       | 872 |\n",
       "| too       | 879 |\n",
       "| union     | 904 |\n",
       "| unite     | 906 |\n",
       "| use       | 912 |\n",
       "| usual     | 913 |\n",
       "| value     | 914 |\n",
       "| various   | 915 |\n",
       "| video     | 917 |\n",
       "| wee       | 937 |\n",
       "| you       | 979 |\n",
       "\n"
      ],
      "text/plain": [
       "   word      i  \n",
       "1  a           1\n",
       "2  about       3\n",
       "3  achieve     7\n",
       "4  again      20\n",
       "5  age        22\n",
       "6  ago        24\n",
       "7  agree      25\n",
       "8  air        26\n",
       "9  america    36\n",
       "10 area       49\n",
       "11 argue      50\n",
       "12 associate  57\n",
       "13 available  62\n",
       "14 aware      63\n",
       "15 because    80\n",
       "16 believe    86\n",
       "17 cause     134\n",
       "18 colleague 166\n",
       "19 die       228\n",
       "20 due       250\n",
       "21 eat       256\n",
       "22 educate   258\n",
       "23 encourage 268\n",
       "24 equal     276\n",
       "25 europe    278\n",
       "26 eye       296\n",
       "27 house     406\n",
       "28 idea      412\n",
       "29 imagine   415\n",
       "30 issue     434\n",
       "31 leave     465\n",
       "32 lie       472\n",
       "33 measure   513\n",
       "34 obvious   565\n",
       "35 one       577\n",
       "36 operate   580\n",
       "37 out       590\n",
       "38 piece     620\n",
       "39 quiet     670\n",
       "40 quite     671\n",
       "41 radio     672\n",
       "42 raise     674\n",
       "43 realise   681\n",
       "44 receive   684\n",
       "45 require   699\n",
       "46 see       734\n",
       "47 serious   741\n",
       "48 situate   771\n",
       "49 tea       842\n",
       "50 tie       872\n",
       "51 too       879\n",
       "52 union     904\n",
       "53 unite     906\n",
       "54 use       912\n",
       "55 usual     913\n",
       "56 value     914\n",
       "57 various   915\n",
       "58 video     917\n",
       "59 wee       937\n",
       "60 you       979"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- tibble(word = words, i = seq_along(words))\n",
    "df %>% filter(str_count(word, \"[aeiou]\")>str_count(word, \"[^aeiou]\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(5)** Define the variable `regex3` such that it matches the three character sequence `\"'\\`. Note that this sequence consists of a double quote, a single quote, and a backslash. _1 point_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex3 = \"\\\"'\\\\\\\\\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
